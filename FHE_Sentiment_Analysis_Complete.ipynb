{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analyse de Sentiment avec Chiffrement Homomorphique Complet (FHE)\n",
        "\n",
        "Ce notebook contient l'ensemble du projet pour l'analyse de sentiment avec FHE.\n",
        "\n",
        "**Etapes:**\n",
        "1. Installation des dependances\n",
        "2. Definition de la classe TextProcessor\n",
        "3. Definition des utilitaires du modele\n",
        "4. Chargement et preparation des donnees\n",
        "5. Entrainement du modele\n",
        "6. Compilation pour FHE\n",
        "7. Test des predictions FHE\n",
        "8. Demonstration interactive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Etape 1: Installation des Dependances\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installation de tous les packages requis\n",
        "# Cette etape peut prendre quelques minutes\n",
        "%pip install -q concrete-ml transformers datasets torch scikit-learn xgboost gradio numpy pandas tqdm\n",
        "\n",
        "print(\"Installation terminee!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Etape 2: Import des Bibliotheques\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from typing import List\n",
        "import tqdm\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from datasets import load_dataset\n",
        "import time\n",
        "import warnings\n",
        "import pickle\n",
        "import os\n",
        "from pathlib import Path\n",
        "from concrete.ml.sklearn import XGBClassifier\n",
        "from concrete.ml.deployment import FHEModelDev\n",
        "import gradio as gr\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Toutes les bibliotheques ont ete importees avec succes!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Etape 3: Classe TextProcessor\n",
        "\n",
        "Cette classe convertit le texte en representations vectorielles utilisables par le modele FHE.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TextProcessor:\n",
        "    \"\"\"Classe pour transformer le texte en representations vectorielles avec RoBERTa.\"\"\"\n",
        "    \n",
        "    def __init__(self, model_name: str = \"cardiffnlp/twitter-roberta-base-sentiment-latest\", device: str = None):\n",
        "        \"\"\"Initialise le processeur de texte.\"\"\"\n",
        "        if device is None:\n",
        "            self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "        else:\n",
        "            self.device = device\n",
        "            \n",
        "        print(f\"Chargement du modele {model_name} sur {self.device}...\")\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "        \n",
        "    def text_to_tensor(self, texts: List[str], batch_size: int = 32) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        TRANSFORMATION TEXTE EN VECTEUR NUMERIQUE (EN CLAIR)\n",
        "        \n",
        "        Convertit le texte en representation vectorielle de 768 dimensions avec RoBERTa.\n",
        "        Cette etape est EN CLAIR (avant le chiffrement FHE).\n",
        "        \n",
        "        ETAPES:\n",
        "        1. TOKENIZATION: Le texte est divise en tokens (mots/sous-mots)\n",
        "        2. ENCODING: Les tokens sont convertis en IDs numeriques\n",
        "        3. ROERTA: Passage a travers le modele RoBERTa pre-entraine\n",
        "        4. EXTRACTION: Recuperation des etats caches (representations internes)\n",
        "        5. POOLING: Moyenne des representations pour obtenir un vecteur par texte\n",
        "        \n",
        "        RESULTAT:\n",
        "        - Format: Array numpy (n_texts, 768)\n",
        "        - Type: float32 (valeurs reelles)\n",
        "        - Dimensions: 768 (taille de la couche cachee de RoBERTa)\n",
        "        \n",
        "        IMPORTANT: Cette etape est EN CLAIR (avant le chiffrement FHE)\n",
        "        \"\"\"\n",
        "        if isinstance(texts, str):\n",
        "            texts = [texts]\n",
        "            \n",
        "        # ETAPE 1: TOKENIZATION\n",
        "        tokenized_texts = [\n",
        "            self.tokenizer.encode(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "            for text in texts\n",
        "        ]\n",
        "        \n",
        "        output_hidden_states_list = []\n",
        "        \n",
        "        # ETAPE 2: TRAITEMENT PAR BATCH (pour l'efficacite)\n",
        "        for i in tqdm.tqdm(range(0, len(tokenized_texts), batch_size), desc=\"Traitement des textes\"):\n",
        "            batch = tokenized_texts[i:i + batch_size]\n",
        "            \n",
        "            # ETAPE 3: PADDING (alignement des longueurs)\n",
        "            max_len = max(t.shape[1] for t in batch)\n",
        "            batch_tensors = []\n",
        "            \n",
        "            for tokens in batch:\n",
        "                if tokens.shape[1] < max_len:\n",
        "                    padding = torch.zeros(1, max_len - tokens.shape[1], dtype=tokens.dtype)\n",
        "                    tokens = torch.cat([tokens, padding], dim=1)\n",
        "                batch_tensors.append(tokens)\n",
        "            \n",
        "            batch_tensor = torch.cat(batch_tensors, dim=0).to(self.device)\n",
        "            \n",
        "            # ETAPE 4: PASSAGE A TRAVERS ROERTA\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(batch_tensor, output_hidden_states=True)\n",
        "                hidden_states = outputs.hidden_states[-1]\n",
        "                # ETAPE 5: POOLING (moyenne sur les tokens)\n",
        "                text_representations = hidden_states.mean(dim=1)\n",
        "                text_representations = text_representations.cpu().numpy()\n",
        "                \n",
        "            output_hidden_states_list.append(text_representations)\n",
        "        \n",
        "        # RESULTAT FINAL: (n_texts, 768) en float32\n",
        "        # RAPPEL: Ces donnees sont EN CLAIR, elles seront chiffrees plus tard\n",
        "        return np.concatenate(output_hidden_states_list, axis=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Etape 4: Utilitaires du Modele\n",
        "\n",
        "Fonctions pour compiler, sauvegarder et charger le modele FHE.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compile_model(model: XGBClassifier, X_sample):\n",
        "    \"\"\"\n",
        "    ETAPE CRITIQUE: Compiler le modele pour l'execution FHE.\n",
        "    \n",
        "    Cette fonction transforme le modele XGBoost en circuit cryptographique FHE.\n",
        "    \n",
        "    CE QUI SE PASSE:\n",
        "    1. QUANTIFICATION: Conversion float → entiers (necessaire pour FHE)\n",
        "       - Les valeurs float sont arrondies et converties en entiers\n",
        "       - La precision est reduite (n_bits, typiquement 2-3 bits)\n",
        "       - Exemple: 0.75 → 3 (si n_bits=2, on a 4 valeurs possibles: 0,1,2,3)\n",
        "    \n",
        "    2. COMPILATION: Transformation du modele en circuit FHE\n",
        "       - Le modele XGBoost est converti en operations cryptographiques\n",
        "       - Chaque operation (addition, multiplication) devient une operation FHE\n",
        "       - Generation des cles cryptographiques (cle secrete, cle publique, cles d'evaluation)\n",
        "    \n",
        "    3. CIRCUIT FHE: Creation d'un circuit executable sur donnees chiffrees\n",
        "       - Le circuit peut traiter des ciphertexts (donnees chiffrees)\n",
        "       - Les resultats sont aussi des ciphertexts\n",
        "    \"\"\"\n",
        "    print(\"Compilation du modele pour FHE (cela peut prendre quelques minutes)...\")\n",
        "    # ICI: Quantification + Compilation en circuit FHE\n",
        "    # Concrete-ML fait automatiquement:\n",
        "    # - Quantification des donnees X_sample (float → int)\n",
        "    # - Transformation du modele en circuit FHE\n",
        "    # - Generation des cles cryptographiques\n",
        "    model.compile(X_sample)\n",
        "    print(\"Compilation terminee!\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def save_model(model: XGBClassifier, model_name: str = \"sentiment_fhe_model\"):\n",
        "    \"\"\"\n",
        "    Sauvegarde le modele FHE compile.\n",
        "    \n",
        "    Sauvegarde le modele avec:\n",
        "    - Le circuit FHE compile\n",
        "    - Les cles cryptographiques (cle publique, cles d'evaluation)\n",
        "    - Les parametres de quantification\n",
        "    \"\"\"\n",
        "    os.makedirs(\"models\", exist_ok=True)\n",
        "    \n",
        "    # Sauvegarde du modele FHE avec toutes ses cles\n",
        "    # FHEModelDev encapsule le modele compile + les cles cryptographiques\n",
        "    fhe_api = FHEModelDev(model_name, model)\n",
        "    # Sauvegarde dans models/sentiment_fhe_model/:\n",
        "    # - Le circuit FHE compile\n",
        "    # - Les cles cryptographiques (necessaires pour chiffrement/dechiffrement)\n",
        "    # - Les parametres de quantification\n",
        "    fhe_api.save(\"models/\")\n",
        "    \n",
        "    # Sauvegarder aussi le modele en clair pour reference (optionnel)\n",
        "    with open(f\"models/{model_name}_clear.pkl\", \"wb\") as f:\n",
        "        pickle.dump(model, f)\n",
        "    \n",
        "    print(f\"Modele sauvegarde dans models/{model_name}/\")\n",
        "\n",
        "\n",
        "def load_model(model_name: str = \"sentiment_fhe_model\"):\n",
        "    \"\"\"\n",
        "    Charge un modele FHE sauvegarde.\n",
        "    \n",
        "    Args:\n",
        "        model_name: Nom du modele a charger\n",
        "        \n",
        "    Returns:\n",
        "        Instance FHEModelDev chargee\n",
        "    \"\"\"\n",
        "    model_path = Path(\"models\") / model_name\n",
        "    \n",
        "    if not model_path.exists():\n",
        "        raise FileNotFoundError(f\"Modele non trouve: {model_path}\")\n",
        "    \n",
        "    fhe_api = FHEModelDev(model_name, path=str(model_path.parent))\n",
        "    return fhe_api\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Etape 5: Chargement et Preparation des Donnees\n",
        "\n",
        "Chargement du dataset Amazon Polarity (100 exemples pour la rapidite: 80 train, 20 test).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chargement du dataset (100 exemples pour la rapidite: 80 train, 20 test)\n",
        "print(\"Chargement du dataset...\")\n",
        "dataset = load_dataset(\"amazon_polarity\", split=\"train[:100]\")\n",
        "df = pd.DataFrame(dataset)\n",
        "df = df.rename(columns={\"content\": \"text\", \"label\": \"sentiment\"})\n",
        "\n",
        "print(f\"Dataset charge: {len(df)} exemples\")\n",
        "print(f\"Distribution des sentiments:\\n{df['sentiment'].value_counts()}\")\n",
        "\n",
        "# Preparation des donnees\n",
        "text_X = df['text'].tolist()\n",
        "y = df['sentiment'].values\n",
        "\n",
        "# Division train/test (80/20)\n",
        "text_X_train, text_X_test, y_train, y_test = train_test_split(\n",
        "    text_X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nDonnees d'entrainement: {len(text_X_train)} exemples\")\n",
        "print(f\"Donnees de test: {len(text_X_test)} exemples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Etape 6: Traitement du Texte avec RoBERTa\n",
        "\n",
        "Conversion des textes en representations vectorielles de 768 dimensions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialisation du processeur de texte\n",
        "print(\"Initialisation du processeur de texte RoBERTa...\")\n",
        "processor = TextProcessor()\n",
        "\n",
        "# Transformation des donnees d'entrainement\n",
        "print(\"\\nTransformation des donnees d'entrainement...\")\n",
        "X_train_transformer = processor.text_to_tensor(text_X_train, batch_size=16)\n",
        "\n",
        "# Transformation des donnees de test\n",
        "print(\"Transformation des donnees de test...\")\n",
        "X_test_transformer = processor.text_to_tensor(text_X_test, batch_size=16)\n",
        "\n",
        "print(f\"\\nShape des features d'entrainement: {X_train_transformer.shape}\")\n",
        "print(f\"Shape des features de test: {X_test_transformer.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Etape 7: Entrainement du Modele XGBoost\n",
        "\n",
        "Recherche des meilleurs hyperparametres avec GridSearchCV.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrainement du modele XGBoost avec support FHE\n",
        "print(\"Entrainement du modele XGBoost...\")\n",
        "\n",
        "model = XGBClassifier()\n",
        "parameters = {\n",
        "    \"n_bits\": [2, 3],  # Bits de quantification FHE\n",
        "    \"max_depth\": [1, 2],\n",
        "    \"n_estimators\": [30, 50],\n",
        "    \"n_jobs\": [-1],\n",
        "}\n",
        "\n",
        "print(\"Recherche des meilleurs hyperparametres...\")\n",
        "grid_search = GridSearchCV(\n",
        "    model, \n",
        "    parameters, \n",
        "    cv=3,\n",
        "    n_jobs=1, \n",
        "    scoring=\"accuracy\",\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train_transformer, y_train)\n",
        "\n",
        "print(f\"\\nMeilleur score (CV): {grid_search.best_score_:.4f}\")\n",
        "print(f\"Meilleurs parametres: {grid_search.best_params_}\")\n",
        "\n",
        "best_model = grid_search.best_estimator_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Etape 8: Evaluation du Modele\n",
        "\n",
        "Evaluation sur le jeu de test (20% des donnees).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation sur le jeu de test\n",
        "print(\"Evaluation sur le jeu de test...\")\n",
        "y_pred = best_model.predict(X_test_transformer)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nPrecision sur le test: {accuracy:.4f}\")\n",
        "print(\"\\nRapport de classification:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"\\nMatrice de confusion:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Etape 9: Compilation du Modele pour FHE (CRITIQUE)\n",
        "\n",
        "Cette etape transforme le modele standard en circuit cryptographique FHE executable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ETAPE CRITIQUE: Compiler le modele pour FHE\n",
        "# Cette etape transforme le modele en circuit cryptographique\n",
        "# \n",
        "# CE QUI SE PASSE:\n",
        "# 1. QUANTIFICATION: Float → entiers\n",
        "# 2. COMPILATION: Modele → circuit FHE\n",
        "# 3. GENERATION DES CLES: Cle secrete, cle publique, cles d'evaluation\n",
        "#\n",
        "# X_train_transformer[:100] est utilise comme echantillon pour calibrer\n",
        "# la quantification (determiner les bornes min/max pour chaque feature)\n",
        "\n",
        "print(\"Compilation du modele pour FHE...\")\n",
        "start = time.perf_counter()\n",
        "best_model = compile_model(best_model, X_train_transformer[:100])\n",
        "end = time.perf_counter()\n",
        "print(f\"Temps de compilation: {end - start:.2f} secondes\")\n",
        "\n",
        "# Sauvegarde du modele compile avec ses cles cryptographiques\n",
        "# Le modele est sauvegarde dans models/sentiment_fhe_model/\n",
        "# avec le circuit FHE et toutes les cles necessaires\n",
        "save_model(best_model, \"sentiment_fhe_model\")\n",
        "\n",
        "# Sauvegarde du processeur de texte\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "with open(\"models/text_processor.pkl\", \"wb\") as f:\n",
        "    pickle.dump(processor, f)\n",
        "\n",
        "print(\"\\nModele et processeur sauvegardes avec succes!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Etape 10: Test de Prediction FHE\n",
        "\n",
        "Test du flux complet: Chiffrement → Prediction FHE → Dechiffrement\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test de prediction FHE sur un texte d'exemple\n",
        "test_text = [\"Ce produit est incroyable! Je l'adore!\"]\n",
        "X_test = processor.text_to_tensor(test_text)\n",
        "\n",
        "print(\"Test de prediction FHE...\")\n",
        "print(f\"Texte d'entree: {test_text[0]}\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PROCESSUS DE PREDICTION FHE:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ETAPE 1: Texte → Vecteur (EN CLAIR)\n",
        "print(\"\\nETAPE 1: Texte → Vecteur (EN CLAIR)\")\n",
        "print(f\"Shape: {X_test.shape}\")\n",
        "print(f\"Type: {X_test.dtype}\")\n",
        "print(f\"Premieres 5 valeurs: {X_test[0][:5]}\")\n",
        "\n",
        "# ETAPES 2-5: Prediction FHE (automatique)\n",
        "print(\"\\nETAPES 2-5: Prediction FHE (automatique)\")\n",
        "print(\"  - Quantification: Float → Integer\")\n",
        "print(\"  - Chiffrement: Clair → Ciphertext\")\n",
        "print(\"  - Calcul FHE: Operations sur donnees chiffrees\")\n",
        "print(\"  - Dechiffrement: Ciphertext → Clair\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "# execute_in_fhe=True declenche tout le processus FHE\n",
        "# \n",
        "# CE QUI SE PASSE AUTOMATIQUEMENT DANS best_model.predict():\n",
        "# \n",
        "# 1. QUANTIFICATION (automatique):\n",
        "#    - X (float32) → X_quant (entiers)\n",
        "#    - Conversion selon les parametres de quantification du modele\n",
        "#\n",
        "# 2. CHIFFREMENT (automatique):\n",
        "#    - X_quant → X_chiffre (ciphertext)\n",
        "#    - Utilise la cle publique generee lors de la compilation\n",
        "#    - Les donnees deviennent illisibles (chiffrees)\n",
        "#\n",
        "# 3. PREDICTION FHE (sur donnees chiffrees):\n",
        "#    - Le circuit FHE traite X_chiffre\n",
        "#    - Toutes les operations (additions, multiplications) sont faites sur ciphertext\n",
        "#    - Le modele ne voit jamais les donnees en clair\n",
        "#    - Resultat: Prediction chiffree (ciphertext)\n",
        "#\n",
        "# 4. DECHIFFREMENT (automatique):\n",
        "#    - Prediction chiffree → Prediction en clair\n",
        "#    - Utilise la cle secrete (privee)\n",
        "#    - Resultat final: 0 (negatif) ou 1 (positif)\n",
        "#\n",
        "prediction = best_model.predict(X_test, execute_in_fhe=True)\n",
        "proba = best_model.predict_proba(X_test, execute_in_fhe=True)\n",
        "end = time.perf_counter()\n",
        "\n",
        "sentiment_labels = [\"Negatif\", \"Positif\"]\n",
        "sentiment = sentiment_labels[int(prediction[0])]\n",
        "\n",
        "print(f\"\\nRESULTAT:\")\n",
        "print(f\"  Sentiment: {sentiment}\")\n",
        "print(f\"  Prediction: {int(prediction[0])} (0=Negatif, 1=Positif)\")\n",
        "print(f\"  Probabilites: {proba}\")\n",
        "print(f\"  Temps de traitement FHE: {end - start:.4f} secondes\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUCCES: Prediction terminee sur donnees chiffrees!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Etape 11: Creation du Fichier Zip pour Telechargement\n",
        "\n",
        "Creation d'un fichier zip contenant le modele FHE et le processeur de texte.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creation du fichier zip pour telechargement\n",
        "import zipfile\n",
        "\n",
        "print(\"Creation du fichier zip pour telechargement...\")\n",
        "\n",
        "with zipfile.ZipFile('fhe_model.zip', 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    # Ajout du repertoire du modele FHE\n",
        "    model_dir = Path('models/sentiment_fhe_model')\n",
        "    if model_dir.exists():\n",
        "        for file in model_dir.rglob('*'):\n",
        "            if file.is_file():\n",
        "                zipf.write(file, file.relative_to('models'))\n",
        "    \n",
        "    # Ajout du processeur de texte\n",
        "    proc_file = Path('models/text_processor.pkl')\n",
        "    if proc_file.exists():\n",
        "        zipf.write(proc_file, 'text_processor.pkl')\n",
        "\n",
        "print(\"Fichier zip cree: fhe_model.zip\")\n",
        "print(\"\\nPour telecharger dans Colab, executez la cellule suivante!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Etape 12: Telechargement du Modele (Colab)\n",
        "\n",
        "Telechargez le fichier zip contenant le modele FHE et le processeur de texte.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Telechargement des fichiers du modele\n",
        "from google.colab import files\n",
        "files.download('fhe_model.zip')\n",
        "print(\"Modele telecharge! Extrayez-le dans votre repertoire local 'models/'.\")\n",
        "print(\"\\nStructure attendue apres extraction:\")\n",
        "print(\"models/\")\n",
        "print(\"  sentiment_fhe_model/\")\n",
        "print(\"    (fichiers du modele FHE)\")\n",
        "print(\"  text_processor.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Etape 13: Demonstration Interactive (Optionnel)\n",
        "\n",
        "Interface Gradio pour tester le modele FHE de maniere interactive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chargement du modele pour la demonstration\n",
        "model_api = load_model(\"sentiment_fhe_model\")\n",
        "\n",
        "def analyze_sentiment(text: str, use_fhe: bool = True):\n",
        "    \"\"\"Analyse le sentiment avec des informations etape par etape.\"\"\"\n",
        "    if not text or len(text.strip()) == 0:\n",
        "        return \"Veuillez entrer un texte a analyser.\"\n",
        "    \n",
        "    try:\n",
        "        # ETAPE 1: Texte → Vecteur (EN CLAIR)\n",
        "        X = processor.text_to_tensor([text])\n",
        "        \n",
        "        result = f\"ETAPE 1: Texte → Vecteur (EN CLAIR)\\n\"\n",
        "        result += f\"Shape: {X.shape}, Type: {X.dtype}\\n\"\n",
        "        result += f\"Premieres 5 valeurs: {X[0][:5]}\\n\\n\"\n",
        "        \n",
        "        if use_fhe:\n",
        "            result += \"ETAPES 2-5: Processus FHE (Automatique)\\n\"\n",
        "            result += \"  - Quantification: Float → Integer\\n\"\n",
        "            result += \"  - Chiffrement: Clair → Ciphertext\\n\"\n",
        "            result += \"  - Calcul FHE: Sur donnees chiffrees\\n\"\n",
        "            result += \"  - Dechiffrement: Ciphertext → Clair\\n\\n\"\n",
        "            \n",
        "            start = time.time()\n",
        "            prediction = model_api.predict(X, execute_in_fhe=True)\n",
        "            elapsed = time.time() - start\n",
        "            \n",
        "            sentiment_labels = [\"Negatif\", \"Positif\"]\n",
        "            sentiment = sentiment_labels[int(prediction[0])]\n",
        "            \n",
        "            result += f\"RESULTAT:\\n\"\n",
        "            result += f\"  Sentiment: {sentiment}\\n\"\n",
        "            result += f\"  Prediction: {int(prediction[0])}\\n\"\n",
        "            result += f\"  Temps: {elapsed:.4f}s\"\n",
        "        else:\n",
        "            prediction = model_api.predict(X, execute_in_fhe=False)\n",
        "            sentiment_labels = [\"Negatif\", \"Positif\"]\n",
        "            sentiment = sentiment_labels[int(prediction[0])]\n",
        "            result += f\"Resultat (Clair): {sentiment}\"\n",
        "        \n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return f\"Erreur: {str(e)}\"\n",
        "\n",
        "# Creation de l'interface Gradio\n",
        "demo = gr.Interface(\n",
        "    fn=analyze_sentiment,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Entrez votre texte\", placeholder=\"Ex: Ce produit est incroyable!\"),\n",
        "        gr.Checkbox(label=\"Utiliser FHE\", value=True)\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Resultat\", lines=10),\n",
        "    title=\"Analyse de Sentiment avec FHE\",\n",
        "    description=\"Analysez le sentiment tout en gardant les donnees chiffrees pendant le traitement.\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
